# ğŸ¤Ÿ Sign Language Recognition using Deep Learning

This project detects and translates **American Sign Language (ASL)** hand gestures into spoken letters using **real-time video**, a **Convolutional Neural Network (CNN)** model, and **text-to-speech (TTS)**. It supports both **single and two-hand gestures**, including complex signs like the letter **Z**.

---

## ğŸ”§ Features

- ğŸ“· Real-time webcam-based gesture recognition
- ğŸ§  Trained CNN model using ASL image dataset
- ğŸ”¤ Recognizes A-Z and 0-9 (36 classes)
- ğŸ”ˆ Text-to-speech audio output using `pyttsx3`
- âœŒï¸ Two-hand gesture support (e.g., for "Z")
- âš¡ Fast and lightweight prediction loop
- ğŸ§¼ Data preprocessing notebook included

---

## ğŸ“ Project Structure

