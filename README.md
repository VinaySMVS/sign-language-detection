# 🤟 Sign Language Recognition using Deep Learning

This project detects and translates **American Sign Language (ASL)** hand gestures into spoken letters using **real-time video**, a **Convolutional Neural Network (CNN)** model, and **text-to-speech (TTS)**. It supports both **single and two-hand gestures**, including complex signs like the letter **Z**.

---

## 🔧 Features

- 📷 Real-time webcam-based gesture recognition
- 🧠 Trained CNN model using ASL image dataset
- 🔤 Recognizes A-Z and 0-9 (36 classes)
- 🔈 Text-to-speech audio output using `pyttsx3`
- ✌️ Two-hand gesture support (e.g., for "Z")
- ⚡ Fast and lightweight prediction loop
- 🧼 Data preprocessing notebook included

---

## 📁 Project Structure

