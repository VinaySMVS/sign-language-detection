# ğŸ¤Ÿ Sign Language Recognition using Deep Learning

This project detects and translates **American Sign Language (ASL)** hand gestures into spoken letters using **real-time video**, a **Convolutional Neural Network (CNN)** model, and **text-to-speech (TTS)**. It supports both **single and two-hand gestures**, including complex signs like the letter **Z**.

---

## ğŸ”§ Features

- ğŸ“· Real-time webcam-based gesture recognition
- ğŸ§  Trained CNN model using ASL image dataset
- ğŸ”¤ Recognizes A-Z and 0-9 (36 classes)
- ğŸ”ˆ Text-to-speech audio output using `pyttsx3`
- âœŒï¸ Two-hand gesture support (e.g., for "Z")
- âš¡ Fast and lightweight prediction loop
- ğŸ§¼ Data preprocessing notebook included

---

## ğŸ“ Project Structure

SignLanguageRecognition/
â”‚
â”œâ”€â”€ model/
â”‚ â””â”€â”€ asl_model.h5 # Trained CNN model
â”œâ”€â”€ sign_language_detect.py # Real-time gesture recognition script
â”œâ”€â”€ data_preprocessing.ipynb # Notebook for dataset loading & training
â”œâ”€â”€ requirements.txt # List of required Python packages
â”œâ”€â”€ sample_images/ # Example hand signs (optional)
â””â”€â”€ README.md # Project info (you're here!)


---

## ğŸš€ How to Run

### 1. Clone the Repository

git clone https://github.com/VinaySMVS/sign-language-detection.git
cd sign-language-detection
---
### 2. Install Requirements
pip install -r requirements.txt
---
### 3. Run the Detection Script
python sign_language_detect.py
---
Your webcam will start, and the recognized ASL letters will be displayed and spoken.
---
###4. Train the Model (Optional)
jupyter notebook data_preprocessing.ipynb
---
Follow the steps in the notebook to preprocess data and train the model. The final model will be saved as asl_model.h5.
ğŸ§  Model Info
Input size: 64x64 RGB images

Model: Convolutional Neural Network (CNN)

Output: 36 softmax units (26 letters + 10 digits)

Optimizer: Adam

Loss: Categorical Crossentropy

Validation Accuracy: > 99%

ğŸ¯ Dataset
You can use any open ASL dataset such as:

Kaggle's ASL Alphabet

Custom images captured using webcam

Each class should have folders of labeled images (A-Z, 0-9).
ğŸ“¦ Requirements
These are listed in requirements.txt, but for reference:

opencv-python
tensorflow
numpy
pyttsx3
mediapipe

Install with:
pip install -r requirements.txt
ğŸ§  Future Enhancements
Add sentence formation using time-sequenced gestures

Upload web demo using Streamlit or Flask

Include regional sign languages (e.g., ISL)

Mobile app integration with TensorFlow Lite

Gesture smoothing to reduce flickering predictions

ğŸ‘¤ Author
Vinay SMVS
ğŸ”— GitHub
ğŸ“§ Email: vcpdeloli@gmail.com
